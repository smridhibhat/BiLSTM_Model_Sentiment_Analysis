{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59262e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-21 15:26:04.112186: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/smridhibhat/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense,Bidirectional\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from keras.layers import *\n",
    "from sklearn.model_selection import cross_val_score \n",
    "import nltk\n",
    "import pandas as pd\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "850f56bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('isear.csv',header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0de64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         0                                                  1\n",
      "0      joy  [ On days when I feel close to my partner and ...\n",
      "1     fear  Every time I imagine that someone I love or I ...\n",
      "2    anger  When I had been obviously unjustly treated and...\n",
      "3  sadness  When I think about the short time that we live...\n",
      "4  disgust  At a gathering I found myself involuntarily si...\n"
     ]
    }
   ],
   "source": [
    "# The isear.csv contains rows with value 'No response'\n",
    "# We need to remove such rows\n",
    "df.drop(df[df[1] == '[ No response.]'].index, inplace = True)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d289a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The feel_arr will store all the sentences\n",
    "# i.e feel_arr is the list of all sentences\n",
    "feel_arr = df[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56ad73d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'On', 'days', 'when', 'I', 'feel', 'close', 'to', 'my', 'partner', 'and', 'other', 'friends', '.', 'When', 'I', 'feel', 'at', 'peace', 'with', 'myself', 'and', 'also', 'experience', 'a', 'close', 'contact', 'with', 'people', 'whom', 'I', 'regard', 'greatly', '.', ']']\n"
     ]
    }
   ],
   "source": [
    "# Each  sentence in feel_arr is tokenized by the help of work tokenizer.\n",
    "# If I have a sentence - 'I am happy'. \n",
    "# After word tokenizing it will convert into- ['I','am','happy']\n",
    "feel_arr = [word_tokenize(sent) for sent in feel_arr]\n",
    "print(feel_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84b9189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a function padd in which each sentence length\n",
    "# is fixed to 100.\n",
    "# If length is less than 100 , then \n",
    "# the word- '<padd>' is append\n",
    "def padd(arr):\n",
    "    for i in range(100-len(arr)):\n",
    "        arr.append('<pad>')\n",
    "    return arr[:100]\n",
    "  \n",
    "# call the padd function for each sentence in feel_arr\n",
    "for i in range(len(feel_arr)):\n",
    "    feel_arr[i]=padd(feel_arr[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49c00e78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[', 'On', 'days', 'when', 'I', 'feel', 'close', 'to', 'my', 'partner', 'and', 'other', 'friends', '.', 'When', 'I', 'feel', 'at', 'peace', 'with', 'myself', 'and', 'also', 'experience', 'a', 'close', 'contact', 'with', 'people', 'whom', 'I', 'regard', 'greatly', '.', ']', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>', '<pad>']\n"
     ]
    }
   ],
   "source": [
    "print(feel_arr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b03976bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Glove vector contains a 50 dimensional vector corresponding \n",
    "# to each word in dictionary.\n",
    "vocab_f = 'glove.6B.50d.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "848c8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings_index is a dictionary which contains the mapping of\n",
    "# word with its corresponding 50d vector.\n",
    "embeddings_index = {}\n",
    "with open(vocab_f,encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        # splitting each line of the glove.6B.50d in a list of \n",
    "        # items- in which the first element is the word to be embedded,\n",
    "        # and from second to the end of line contains the 50d vector.\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f9b9ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.092086  0.2571   -0.58693  -0.37029   1.0828   -0.55466  -0.78142\n",
      "  0.58696  -0.58714   0.46318  -0.11267   0.2606   -0.26928  -0.072466\n",
      "  1.247     0.30571   0.56731   0.30509  -0.050312 -0.64443  -0.54513\n",
      "  0.86429   0.20914   0.56334   1.1228   -1.0516   -0.78105   0.29656\n",
      "  0.7261   -0.61392   2.4225    1.0142   -0.17753   0.4147   -0.12966\n",
      " -0.47064   0.3807    0.16309  -0.323    -0.77899  -0.42473  -0.30826\n",
      " -0.42242   0.055069  0.38267   0.037415 -0.4302   -0.39442   0.10511\n",
      "  0.87286 ]\n"
     ]
    }
   ],
   "source": [
    "# the embedding index of word 'happy'\n",
    "print( embeddings_index['happy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "227cb496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding each word of the feel_arr\n",
    "embedded_feel_arr=[] \n",
    "for each_sentence in feel_arr:\n",
    "    embedded_feel_arr.append([])\n",
    "    for word in each_sentence:\n",
    "        if word.lower() in embeddings_index:\n",
    "            embedded_feel_arr[-1].append(embeddings_index[word.lower()])\n",
    "        else:\n",
    "            # if the word to be embedded is '<padd>' append 0 fifty times\n",
    "            embedded_feel_arr[-1].append([0]*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36b47346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.61201   0.98226   0.11539   0.014623  0.23873  -0.067035  0.30632\n",
      " -0.64742  -0.38517  -0.03691   0.094788  0.57631  -0.091557 -0.54825\n",
      "  0.25255  -0.14759   0.13023   0.21658  -0.30623   0.30028  -0.23471\n",
      " -0.17927   0.9518    0.54258   0.31172  -0.51038  -0.65223  -0.48858\n",
      "  0.13486  -0.40132   2.493    -0.38777  -0.26456  -0.49414  -0.3871\n",
      " -0.20983   0.82941  -0.46253   0.39549   0.014881  0.79485  -0.79958\n",
      " -0.16243   0.013862 -0.53536   0.52536   0.019818 -0.16353   0.30649\n",
      "  0.81745 ]\n"
     ]
    }
   ],
   "source": [
    "print(embedded_feel_arr[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35c3e789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7575, 100, 50)\n"
     ]
    }
   ],
   "source": [
    "#Converting x into numpy-array\n",
    "X = np.array(embedded_feel_arr)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "da3dde62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform one-hot encoding on df[0] i.e emotion\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "Y = enc.fit_transform(np.array(df[0]).reshape(-1,1)).toarray()\n",
    "\n",
    "# Split into train and test\n",
    "from keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Defining the BiLSTM Model\n",
    "def model(X,Y,input_size1,input_size2,output_size):\n",
    "    m = Sequential()\n",
    "    m.add(Bidirectional(LSTM(100,input_shape=(input_size1,input_size2))))\n",
    "    m.add(Dropout(0.5))\n",
    "    m.add(Dense(output_size,activation='softmax'))\n",
    "    m.compile('Adam','categorical_crossentropy',['accuracy'])\n",
    "    m.fit(X,Y,epochs=32, batch_size=128)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415ef426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "48/48 [==============================] - 27s 481ms/step - loss: 1.8895 - accuracy: 0.2165\n",
      "Epoch 2/32\n",
      "48/48 [==============================] - 23s 486ms/step - loss: 1.7157 - accuracy: 0.3343\n",
      "Epoch 3/32\n",
      "48/48 [==============================] - 26s 538ms/step - loss: 1.6271 - accuracy: 0.3767\n",
      "Epoch 4/32\n",
      "48/48 [==============================] - 27s 564ms/step - loss: 1.5769 - accuracy: 0.3965\n",
      "Epoch 5/32\n",
      "48/48 [==============================] - 29s 591ms/step - loss: 1.5368 - accuracy: 0.4144\n",
      "Epoch 6/32\n",
      "48/48 [==============================] - 25s 529ms/step - loss: 1.4960 - accuracy: 0.4388\n",
      "Epoch 7/32\n",
      "48/48 [==============================] - 27s 567ms/step - loss: 1.4740 - accuracy: 0.4485\n",
      "Epoch 8/32\n",
      "48/48 [==============================] - 40s 833ms/step - loss: 1.4500 - accuracy: 0.4625\n",
      "Epoch 9/32\n",
      "48/48 [==============================] - 47s 968ms/step - loss: 1.4453 - accuracy: 0.4571\n",
      "Epoch 10/32\n",
      "48/48 [==============================] - 53s 1s/step - loss: 1.3760 - accuracy: 0.4848\n",
      "Epoch 11/32\n",
      "45/48 [===========================>..] - ETA: 6s - loss: 1.3689 - accuracy: 0.4938"
     ]
    }
   ],
   "source": [
    "# calling the model function with the traning data inorder to build the model\n",
    "bilstmModel = model(X_train,Y_train,100,50,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "546645fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bidirectional_3 (Bidirecti  (None, 200)               120800    \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 200)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 7)                 1407      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122207 (477.37 KB)\n",
      "Trainable params: 122207 (477.37 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# print the summary of the model\n",
    "bilstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7940097c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48/48 [==============================] - 2s 19ms/step - loss: 1.5037 - accuracy: 0.5122\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5037239789962769, 0.5122112035751343]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Testing the model\n",
    "bilstmModel.evaluate(X_test,Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15773709",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Checking the results of our model with user given sentences stored in test.csv file\n",
    "\n",
    "df_test = pd.read_csv('test.csv',header = None)\n",
    "df_test.drop(df[df[1] == '[ No response.]'].index, inplace = True)\n",
    "feel_arr_test=df_test[1]\n",
    "\n",
    "\n",
    "feel_arr_test=[word_tokenize(sent) for sent in feel_arr_test]\n",
    "\n",
    "for i in range(len(feel_arr1)):\n",
    "    feel_arr_test[i]=padd(feel_arr_test[i])\n",
    "\n",
    "embedded_feel_arr_test=[] \n",
    "for each_sentence in feel_arr_test:\n",
    "    embedded_feel_arr_test.append([])\n",
    "    for word in each_sentence:\n",
    "        if word.lower() in embeddings_index:\n",
    "            embedded_feel_arr_test[-1].append(embeddings_index[word.lower()])\n",
    "        else:\n",
    "            embedded_feel_arr_test[-1].append([0]*50)\n",
    "            \n",
    "X_test = np.array(embedded_feel_arr_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "79ee9f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 98ms/step\n"
     ]
    }
   ],
   "source": [
    "prediction = bilstmModel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e5d53f54",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.11344204, 0.15389065, 0.14762376, 0.1799428 , 0.05881096,\n",
       "       0.12434127, 0.22194855], dtype=float32)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sentence: 'Grovelling people.' , Emotion: Digust.\n",
    "# highest value of the prediction list is 0.22194855(at the last index 6) which is the index of disgust emotion\n",
    "prediction[4]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
